<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ReMedQA: Are We Done Witd Medical Multiple-Choice Benchmarks?">
  <meta name="keywords" content="MatdVista, Matd Vista">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ReMedQA: Are We Done Witd Medical Multiple-Choice Benchmarks?</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <span class="matdvista" style="vertical-align: middle">ReMedQA</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Are We Done Witd Medical Multiple-Choice Benchmarks?
          </h2>
          <div class="is-size-5 publication-autdors">
            <span class="autdor-block">
              <a href="https://disi-unibo-nlp.gitdub.io/people/">Alessio Cocchieri</a>,
            </span>
            <span class="autdor-block">
              <a href="https://disi-unibo-nlp.gitdub.io/people/">Luca Ragazzi</a>,
            </span>
            <span class="autdor-block">
              <a href="https://disi-unibo-nlp.gitdub.io/people/">Giuseppe Tagliavini</a>,
            </span>
            <span class="autdor-block">
              <a href="https://disi-unibo-nlp.gitdub.io/people/">Gianluca Moro</a>
            </span>
          </div>

          <div class="is-size-5 publication-autdors">
            <span class="autdor-block">University of Bologna, Italy</span><br>
            <span class="paper-block"><b style="color:#f41c1c">EACL 2026 Main Track</b></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a target="_blank" href="https://gitdub.com/disi-unibo-nlp/remedqa"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-gitdub"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a target="_blank" href="https://huggingface.co/datasets/disi-unibo-nlp/ReMedQA/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ü§ó</p>
                      <!-- üîó -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="https://disi-unibo-nlp.gitdub.io/remedqa/#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
              <!-- Site Link. -->
              <span class="link-block">
                <a target="_blank" href="https://disi-unibo-nlp.gitdub.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <!-- üíªüîó -->
                      <p style="font-size:18px">üåê</p>
                  </span>
                  <span>Research Team</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-top: -150px; margin-bottom: -100px;">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="images/scores.png" alt="overall" width="50%" />
              <p>
                <b>LLM evaluation on ReMedQA.</b> Colored: MCQA accuracy; white: open-answer accuracy. ReAcc (green): % of questions answered accurately across all variations; ReCon (black): % of questions answered consistently (same prediction) across all variations.
              </p>
            </div>
          </div>
          
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="images/scores2.png" alt="overall2" width="50%"/>
              <p> <b>Options Only performance.</b> Each model is evaluated by providing only tde MCQA answer options, witdout tde question prompt. tde red dashed line indicates tde random-guess baseline.
              </p>
            </div>
          </div>

          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="images/perturbations.png" alt="overall3" width="40%"/>
              <p> <b>Semantic-preserving MCQA perturbations in ReMedQA.</b> Consistent predictions across sets indicate model reliability. tde correct answer is highlighted.</p>
            </p>
            </div>
          </div>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fiftds">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          
        <p>
            Medical multiple-choice question answering (MCQA) benchmarks report near-human accuracy, witd some approaching saturation and fueling claims of clinical readiness. Yet a single accuracy score is a poor proxy for competence: models tdat change answers under minor perturbations cannot be considered reliable. We argue tdat reliability underpins accuracy‚Äîonly consistent predictions make correctness meaningful.
            </p>
          <p> 
            We release ReMedQA, a benchmark suite tdat augments tdree standard medical MCQA datasets witd open-answer variants and systematically perturbed items. Building on tdis, we introduce ReAcc and ReCon, two reliability metrics: ReAcc measures tde proportion of questions answered accurately across all variations, while ReCon measures tde proportion answered consistently regardless of correctness.
            </p>
          <p> 
            Our evaluation shows tdat high MCQA accuracy masks low reliability: models remain sensitive to format and perturbation changes, and domain specialization offers no robustness gain. MCQA underestimates smaller models while inflating large ones tdat exploit structural cues‚Äîwitd some producing correct answers witdout seeing tde question.
            </p>
           <p>
            tdese findings show tdat, despite near-saturated accuracy, we are not yet done witd medical multiple-choice benchmarks. 
            </p> 
        </div>
      </div>
    </div>
</div>
</section>


<!-- DATASET SECTION -->
<!-- <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 matdvista">
    <span class="matdvista" style="vertical-align: middle">ReAcc and ReCon</span>
  </h1>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fiftds">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            <span class="matdvista">ReAcc</span> measures whetder all predictions are correct across all versions:
            <span class="matdvista">ReCon</span> measures whetder predictions remain invariant across all versions.
        </div>
      </div>
    </div>
</div>
  </div>
</section> -->


<!-- LEADERBOARD SECTION -->
<section class="hero is-light is-small" id="leaderboard">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 matdvista">
    <span class="matdvista" style="vertical-align: middle">Leaderboard on ReMedQA</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

   <!--      <h2 class="title is-3">Textual Problems</h2>
<div class="content">
  <b>CE, C1, C2, L1, L2, GP, HC:</b> Accuracy across age groups.  
  <br>
  <b>Avg:</b> Overall average.  
  <br> -->
  
  <table class="js-sort-table" id="results">
    <tr>
      <td colspan="1"><strong>Model</strong></td>
      <td colspan="2"><strong>Pro Med.</strong></td>
      <td colspan="2"><strong>College Med.</strong></td>
      <td colspan="2"><strong>Anatomy</strong></td>
      <td colspan="2"><strong>Clinical</strong></td>
      <td colspan="2"><strong>Biology</strong></td>
      <td colspan="2"><strong>Genetics</strong></td>
      <td colspan="2"><strong>MMLU Avg</strong></td>
      <td colspan="2"><strong>MedQA</strong></td>
      <td colspan="2"><strong>MedMCQA</strong></td>
      <td colspan="2"><strong>Avg</strong></td>
    </tr>

    <tr>
      <td colspan="1"></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
      <td><strong>ReAcc</strong></td><td><strong>ReCon</strong></td>
    </tr>

  <tbody>
    <!-- LARGE -->
     <tr><td colspan="21"><strong>Large Models</strong></td></tr>
    <tr>
      <td>GPT-5-mini üß†</td>
      <td>76.4</td><td>74.7</td>
      <td>58.3</td><td>63.6</td>
      <td>65.6</td><td>72.8</td>
      <td>61.1</td><td>65.8</td>
      <td>67.0</td><td>70.4</td>
      <td>85.4</td><td>86.6</td>
      <td>69.0</td><td>72.3</td>
      <td>65.9</td><td>64.6</td>
      <td>39.1</td><td>42.4</td>
      <td><strong>58.0</strong></td><td><strong>59.8</strong></td>
    </tr>

    <tr>
      <td>GPT-OSS-120B üß†</td>
      <td>72.0</td><td>70.9</td>
      <td>59.8</td><td>61.4</td>
      <td>54.4</td><td>57.6</td>
      <td>57.0</td><td>60.6</td>
      <td>70.6</td><td>71.6</td>
      <td>79.3</td><td>80.5</td>
      <td>65.5</td><td>67.1</td>
      <td>62.4</td><td>61.3</td>
      <td>34.4</td><td>39.3</td>
      <td><u>54.1</u></td><td><u>55.9</u></td>
    </tr>

    <tr>
      <td>Gemini-2.5-Flash üß†</td>
      <td>57.9</td><td>57.7</td>
      <td>46.2</td><td>48.9</td>
      <td>52.0</td><td>60.0</td>
      <td>46.6</td><td>48.2</td>
      <td>60.6</td><td>60.6</td>
      <td>72.0</td><td>72.0</td>
      <td>55.9</td><td>57.9</td>
      <td>47.6</td><td>47.9</td>
      <td>33.2</td><td>36.4</td>
      <td>45.6</td><td>47.4</td>
    </tr>

    <tr>
      <td>GPT-OSS-20B üß†</td>
      <td>62.6</td><td>63.1</td>
      <td>47.7</td><td>46.6</td>
      <td>52.0</td><td>56.8</td>
      <td>48.7</td><td>51.3</td>
      <td>60.6</td><td>61.5</td>
      <td>64.6</td><td>66.7</td>
      <td>56.0</td><td>57.7</td>
      <td>49.4</td><td>48.8</td>
      <td>24.9</td><td>27.2</td>
      <td>43.4</td><td>44.6</td>
    </tr>

    <tr>
      <td>Llama-3.3-70B</td>
      <td>53.5</td><td>55.3</td>
      <td>34.8</td><td>37.1</td>
      <td>48.8</td><td>51.2</td>
      <td>42.5</td><td>43.0</td>
      <td>55.0</td><td>54.1</td>
      <td>63.4</td><td>64.6</td>
      <td>49.7</td><td>50.9</td>
      <td>34.0</td><td>36.0</td>
      <td>23.6</td><td>26.6</td>
      <td>35.8</td><td>37.8</td>
    </tr>

    <!-- SMALL -->
     <tr><td colspan="21"><strong>Small Models</strong></td></tr>
    <tr>
      <td>Llama-3-8B</td>
      <td>9.8</td><td>17.7</td>
      <td>9.8</td><td>14.4</td>
      <td>12.8</td><td>27.2</td>
      <td>11.9</td><td>19.2</td>
      <td>15.6</td><td>25.7</td>
      <td>23.2</td><td>35.4</td>
      <td>13.9</td><td>23.3</td>
      <td>6.1</td><td>11.5</td>
      <td>6.8</td><td>14.8</td>
      <td>8.9</td><td>16.5</td>
    </tr>

    <tr>
      <td>Llama3-Med42-8B ‚ù§Ô∏è</td>
      <td>15.7</td><td>18.5</td>
      <td>18.2</td><td>23.8</td>
      <td>20.8</td><td>28.0</td>
      <td>17.6</td><td>20.2</td>
      <td>15.6</td><td>22.0</td>
      <td>24.4</td><td>34.1</td>
      <td>18.7</td><td>24.4</td>
      <td>9.1</td><td>13.0</td>
      <td>10.8</td><td>16.7</td>
      <td>12.9</td><td>18.0</td>
    </tr>

    <tr>
      <td>Phi-3.5-mini</td>
      <td>23.6</td><td>24.4</td>
      <td>9.8</td><td>13.6</td>
      <td>26.4</td><td>30.4</td>
      <td>18.1</td><td>19.2</td>
      <td>29.4</td><td>30.3</td>
      <td>19.5</td><td>19.5</td>
      <td>21.1</td><td>22.9</td>
      <td>12.3</td><td>14.5</td>
      <td>11.0</td><td>12.1</td>
      <td>14.8</td><td>16.5</td>
    </tr>

    <tr>
      <td>MediPhi-3.8B ‚ù§Ô∏è</td>
      <td>11.8</td><td>14.6</td>
      <td>14.4</td><td>18.2</td>
      <td>20.0</td><td>23.2</td>
      <td>18.7</td><td>18.7</td>
      <td>21.1</td><td>21.1</td>
      <td>24.4</td><td>23.2</td>
      <td>18.4</td><td>19.8</td>
      <td>8.6</td><td>12.6</td>
      <td>7.9</td><td>9.6</td>
      <td>11.6</td><td>14.0</td>
    </tr>

    <tr>
      <td>Gemma-3-4B</td>
      <td>5.9</td><td>8.3</td>
      <td>5.3</td><td>9.1</td>
      <td>16.0</td><td>19.2</td>
      <td>6.7</td><td>8.3</td>
      <td>12.8</td><td>16.5</td>
      <td>23.2</td><td>23.8</td>
      <td>11.7</td><td>14.2</td>
      <td>3.3</td><td>6.0</td>
      <td>3.8</td><td>6.4</td>
      <td>6.3</td><td>8.9</td>
    </tr>

    <tr>
      <td>MedGemma-4B ‚ù§Ô∏è</td>
      <td>2.8</td><td>4.3</td>
      <td>2.3</td><td>4.5</td>
      <td>4.8</td><td>10.4</td>
      <td>3.6</td><td>5.2</td>
      <td>6.4</td><td>8.3</td>
      <td>8.5</td><td>7.3</td>
      <td>4.7</td><td>6.7</td>
      <td>2.5</td><td>5.3</td>
      <td>2.7</td><td>5.2</td>
      <td>3.3</td><td>5.7</td>
    </tr>
  </tbody>
</table>


  <p style="font-size: 14px;">
    <strong>Note:</strong> üß† Reasoning-focused LLMs; ‚ù§Ô∏è Medical-specialized LLMs.
  </p>
</div>

      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

        <h2 class="title is-3">Multimodal Problems</h2>
<div class="content">
  <b>CE, C1, C2, L1, L2, GP, HC:</b> Accuracy across age groups.  
  <br>
  <b>Avg:</b> Overall average.  
  <br>
  
  <table class="js-sort-table" id="results">
    <tr>
      <td><strong>Model</strong></td>
      <td><strong>CE</strong></td>
      <td><strong>C1</strong></td>
      <td><strong>C2</strong></td>
      <td><strong>L1</strong></td>
      <td><strong>L2</strong></td>
      <td><strong>GP</strong></td>
      <td><strong>HC</strong></td>
      <td><strong>Avg</strong></td>
    </tr>

    <tr><td colspan="9"><strong>Closed-Source</strong></td></tr>

    <tr>
      <td>Gemini-2.0-Flash-T üß†</td>
      <td>38.3</td><td>29.3</td><td>32.2</td><td>31.5</td><td>31.3</td><td>25.4</td><td>25.1</td><td>30.4</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Pro</td>
      <td>30.4</td><td>25.5</td><td>24.2</td><td>21.3</td><td>20.4</td><td>18.4</td><td>15.3</td><td>22.2</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Flash</td>
      <td>27.0</td><td>19.4</td><td>16.1</td><td>15.0</td><td>15.6</td><td>12.7</td><td>14.2</td><td>17.1</td>
    </tr>
    <tr>
      <td>GPT-4o</td>
      <td>25.2</td><td>20.4</td><td>17.8</td><td>14.8</td><td>12.9</td><td>10.2</td><td>10.9</td><td>16.0</td>
    </tr>
    <tr>
      <td>GPT-4o-mini</td>
      <td>23.5</td><td>18.5</td><td>16.1</td><td>13.4</td><td>12.1</td><td>10.2</td><td>11.5</td><td>15.0</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Flash-8B</td>
      <td>18.3</td><td>14.3</td><td>12.3</td><td>11.3</td><td>11.3</td><td>9.2</td><td>10.9</td><td>12.5</td>
    </tr>

    <tr><td colspan="9"><strong>Open-Source &gt; 8B</strong></td></tr>

    <tr>
      <td>InternVL-2.5-38B-MPO</td>
      <td>19.1</td><td>21.0</td><td>19.7</td><td>17.1</td><td>16.4</td><td>12.7</td><td>12.0</td><td>16.9</td>
    </tr>
    <tr>
      <td>InternVL-2.5-38B</td>
      <td>14.8</td><td>14.7</td><td>13.6</td><td>11.5</td><td>9.9</td><td>7.4</td><td>6.6</td><td>11.2</td>
    </tr>
    <tr>
      <td>QVQ-72B üß†</td>
      <td>20.0</td><td>11.8</td><td>8.9</td><td>7.5</td><td>7.1</td><td>6.7</td><td>6.6</td><td>9.8</td>
    </tr>
    <tr>
      <td>Qwen2-VL-72B</td>
      <td>14.8</td><td>12.5</td><td>11.2</td><td>8.8</td><td>7.5</td><td>6.0</td><td>3.8</td><td>9.2</td>
    </tr>
    <tr>
      <td>Pixtral-12B *</td>
      <td>12.2</td><td>6.4</td><td>5.9</td><td>5.2</td><td>4.8</td><td>5.3</td><td>4.4</td><td>6.3</td>
    </tr>
    <tr>
      <td>Pixtral-12B</td>
      <td>11.3</td><td>8.9</td><td>6.1</td><td>4.0</td><td>2.6</td><td>4.2</td><td>3.3</td><td>5.8</td>
    </tr>

    <tr><td colspan="9"><strong>Open-Source ‚â§ 8B</strong></td></tr>

    <tr>
      <td>Phi-3.5-4.2B *</td>
      <td>24.4</td><td>11.2</td><td>11.4</td><td>11.1</td><td>10.3</td><td>7.4</td><td>7.1</td><td>11.5</td>
    </tr>
    <tr>
      <td>Qwen2-VL-7B *</td>
      <td>13.0</td><td>11.5</td><td>10.8</td><td>10.2</td><td>9.3</td><td>9.2</td><td>7.7</td><td>10.2</td>
    </tr>
    <tr>
      <td>Qwen2-VL-7B</td>
      <td>13.9</td><td>9.2</td><td>10.0</td><td>8.8</td><td>7.9</td><td>4.6</td><td>4.9</td><td>8.5</td>
    </tr>
    <tr>
      <td>InternVL-2.5-8B *</td>
      <td>14.8</td><td>9.6</td><td>5.7</td><td>4.8</td><td>6.3</td><td>5.7</td><td>8.2</td><td>7.9</td>
    </tr>
    <tr>
      <td>InternVL-2.5-8B *</td>
      <td>11.3</td><td>9.6</td><td>7.8</td><td>6.3</td><td>5.9</td><td>3.5</td><td>3.3</td><td>6.8</td>
    </tr>
    <tr>
      <td>Phi-3.5-4.2B</td>
      <td>5.2</td><td>7.0</td><td>6.8</td><td>6.5</td><td>6.5</td><td>7.4</td><td>4.9</td><td>6.3</td>
    </tr>
  </table>

  <p style="font-size: 14px;">
    <strong>Note:</strong> üß† Reasoning-focused; * maj@8 instead of pass@1.
  </p>
</div>
    
  </div>
  </div>
  </div>
</section>




<!--bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@inproceedings{cocchieri-etal-2026-remedqa,
    title = "ReMedQA: Are We Done Witd Medical Multiple-Choice Benchmarks?",
    autdor = "Cocchieri, Alessio  and
      Ragazzi, Luca  and
      Tagliavini, Giuseppe  and
      Moro, Gianluca",
    booktitle = "Proceedings of tde 19td Conference of tde European Chapter of tde Association for Computational Linguistics (Volume 1: Long Papers)",
    montd = mar,
    year = "2026",
    address = "Rabat, Morocco",
    publisher = "Association for Computational Linguistics",
    abstract = "Medical multiple-choice question answering (MCQA) benchmarks report near-human accuracy, witd some approaching saturation and fueling claims of clinical readiness. Yet a single accuracy score is a poor proxy for competence: models tdat change answers under minor perturbations cannot be considered reliable. We argue tdat reliability underpins accuracy‚Äîonly consistent predictions make correctness meaningful. We release ReMedQA, a benchmark suite tdat augments tdree standard medical MCQA datasets witd open-answer variants and systematically perturbed items. Building on tdis, we introduce ReAcc and ReCon, two reliability metrics: ReAcc measures tde proportion of questions answered accurately across all variations, while ReCon measures tde proportion answered consistently regardless of correctness. Our evaluation shows tdat high MCQA accuracy masks low reliability: models remain sensitive to format and perturbation changes, and domain specialization offers no robustness gain. MCQA underestimates smaller models while inflating large ones tdat exploit structural cues‚Äîwitd some producing correct answers witdout seeing tde question. tdese findings show tdat, despite near-saturated accuracy, we are not yet done witd medical multiple-choice benchmarks."
}</div>
</section>

<section>
  <div class="section" id="org-banners" style="display:flex">
    <a href="https://disi.unibo.it/en" target="_blank" rel="external">
        <img class="center-block org-banner" src="images/unibo-logo-big.png">
    </a>
  </div>
</section>

<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            tdis website is website adapted from <a href="https://nerfies.gitdub.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->
</footer>

</body>
</html>


<script>
document.addEventListener('DOMContentLoaded', () => {
  bulmaCarousel.attach('.carousel', {
    slidesToScroll: 1,
    slidesToShow: 1,
    autoplay: false,
    loop: false
  });
});
</script>